"""
Step 4: æ•°æ®åˆ†æå™¨ï¼ˆå¢å¼ºç‰ˆï¼‰
æ–°å¢åŠŸèƒ½ï¼š
1. ç”ŸæˆRAGå‹å¥½çš„ç»“æ„åŒ–æ´å¯Ÿæ–‡æ¡£
2. å°†ç»Ÿè®¡æ•°æ®è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€æè¿°
3. æä¾›å¯æŸ¥è¯¢çš„æ•°æ®æ‘˜è¦
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import re
from pathlib import Path
from typing import Dict, List, Tuple
from dataclasses import dataclass
import json
from config import Config


@dataclass
class AnalysisInsight:
    """åˆ†ææ´å¯Ÿæ•°æ®ç±»"""
    category: str  # æ´å¯Ÿç±»åˆ«ï¼ˆå¦‚ï¼šåˆ†å¸ƒç»Ÿè®¡ã€å­ç±»åˆ†æç­‰ï¼‰
    title: str  # æ´å¯Ÿæ ‡é¢˜
    content: str  # è‡ªç„¶è¯­è¨€æè¿°
    data: dict  # ç»“æ„åŒ–æ•°æ®
    

class EnhancedDataAnalyzer:
    """å¢å¼ºç‰ˆæ•°æ®åˆ†æå™¨ - ç”ŸæˆRAGå¯ç”¨çš„æ´å¯Ÿ"""
    
    def __init__(self, input_file: str, output_dir: str = "results"):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            input_file: è¾“å…¥CSVæ–‡ä»¶ï¼ˆbatch_classification_results.csvï¼‰
            output_dir: è¾“å‡ºç›®å½•
        """
        self.input_file = input_file
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # åŠ è½½æ•°æ®
        self.df = pd.read_csv(input_file, encoding='utf-8-sig').fillna("")
        self.df['text_len'] = self.df['text'].astype(str).apply(len)
        
        # è®¾ç½®ç»˜å›¾é£æ ¼
        sns.set_theme(style="whitegrid")
        plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Heiti TC', 'SimHei']
        plt.rcParams['axes.unicode_minus'] = False
        
        # å­˜å‚¨ç”Ÿæˆçš„æ´å¯Ÿ
        self.insights: List[AnalysisInsight] = []
    
    def run_full_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print("ğŸ” å¼€å§‹æ•°æ®åˆ†æ...")
        
        # 1. åŸºç¡€ç»Ÿè®¡
        self._analyze_basic_distribution()
        
        # 2. STRONGç±»æ·±åº¦åˆ†æ
        self._analyze_strong_subtypes()
        
        # 3. WEAKç±»å¼•è¯åˆ†æ
        self._analyze_weak_sources()
        
        # 4. NONEç±»æè¿°åˆ†æ
        self._analyze_none_focus()
        
        # 5. ç»¼åˆç»Ÿè®¡
        self._analyze_comprehensive_stats()
        
        # 6. ç”Ÿæˆå¯è§†åŒ–
        self._generate_visualizations()
        
        # 7. å¯¼å‡ºRAGå‹å¥½çš„æ–‡æ¡£
        self._export_rag_documents()
        
        print(f"âœ… åˆ†æå®Œæˆï¼å·²ç”Ÿæˆ {len(self.insights)} æ¡æ´å¯Ÿ")
    
    def _analyze_basic_distribution(self):
        """åˆ†æåŸºç¡€åˆ†å¸ƒ"""
        counts = self.df['resolution_type'].value_counts()
        total = len(self.df)
        
        # ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°
        content = f"""æ•°æ®é›†æ€»ä½“åˆ†å¸ƒæ¦‚å†µï¼š

æœ¬æ•°æ®é›†å…±åŒ…å« {total} æ¡åœ°åè®°å½•ï¼Œåˆ†ç±»åˆ†å¸ƒå¦‚ä¸‹ï¼š

"""
        for label, count in counts.items():
            pct = (count / total * 100)
            content += f"â€¢ **{label}ç±»**ï¼š{count} æ¡ï¼ˆ{pct:.1f}%ï¼‰\n"
        
        # æ·»åŠ è§£é‡Š
        content += """

åˆ†ç±»è¯´æ˜ï¼š
- **STRONGç±»**ï¼šä½œè€…ç›´æ¥é™ˆè¿°çš„å‘½åè§£é‡Šï¼Œæ˜ç¡®æ ‡æ³¨"å› ...æ•…å"ç­‰å› æœå…³ç³»
- **WEAKç±»**ï¼šå¼•ç”¨ä»–äººè¯´æ³•æˆ–å…¸ç±è®°è½½çš„å‘½åè§£é‡Š
- **NONEç±»**ï¼šä»…åŒ…å«åœ°ç†ä½ç½®ã€è·ç¦»ã€è¡Œæ”¿æ²¿é©ç­‰æè¿°ï¼Œä¸æ¶‰åŠå‘½ååŸå› 
"""
        
        self.insights.append(AnalysisInsight(
            category="åŸºç¡€ç»Ÿè®¡",
            title="åœ°åè®°å½•åˆ†ç±»åˆ†å¸ƒ",
            content=content,
            data=counts.to_dict()
        ))
    
    def _analyze_strong_subtypes(self):
        """åˆ†æSTRONGç±»çš„å‘½åé€»è¾‘å­ç±»"""
        strong_df = self.df[self.df['resolution_type'] == 'STRONG'].copy()
        
        if len(strong_df) == 0:
            return
        
        # å®šä¹‰å­ç±»å‹åˆ†ç±»é€»è¾‘
        def get_strong_subtype(text):
            if re.search(r"å±±|å²­|å³°|å²©|å²³|å†ˆ", text):
                return "è‡ªç„¶å±±å²³"
            if re.search(r"æ°´|æ²³|æ±Ÿ|å·|æºª|æ± |æ¹–|æ½­|æº", text):
                return "è‡ªç„¶æ°´æ–‡"
            if re.search(r"äºº|ç‹|å…¬|å§“|æ°|çš‡|å|å¦ƒ", text):
                return "äººç‰©å§“æ°"
            if re.search(r"æ•…|æ—§|æ”¹|å¾™|åºŸ|ç½¢|æ–°ç½®", text):
                return "å†å²æ²¿é©"
            if re.search(r"å–.*?ä¹‹ä¹‰|å–.*?åä¹‹|ä»¥.*?ä¸ºå", text):
                return "æŠ½è±¡è¯­ä¹‰"
            return "å…¶ä»–"
        
        strong_df['logic_type'] = strong_df['text'].apply(get_strong_subtype)
        logic_counts = strong_df['logic_type'].value_counts()
        
        # ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°
        content = f"""STRONGç±»å‘½åé€»è¾‘æ·±åº¦åˆ†æï¼š

åœ¨ {len(strong_df)} æ¡æ˜ç¡®å‘½åè§£é‡Šä¸­ï¼Œå‘½åé€»è¾‘åˆ†å¸ƒå¦‚ä¸‹ï¼š

"""
        for logic, count in logic_counts.items():
            pct = (count / len(strong_df) * 100)
            content += f"â€¢ **{logic}å‹å‘½å**ï¼š{count} æ¡ï¼ˆ{pct:.1f}%ï¼‰\n"
        
        # æ·»åŠ å…¸å‹æ¡ˆä¾‹ï¼ˆå¦‚æœæœ‰ï¼‰
        content += "\n**å…¸å‹æ¡ˆä¾‹**ï¼š\n"
        for logic in logic_counts.head(3).index:
            examples = strong_df[strong_df['logic_type'] == logic].head(2)
            for _, ex in examples.iterrows():
                content += f"- ã€{ex['placename']}ã€‘{ex['text'][:50]}...\n"
        
        self.insights.append(AnalysisInsight(
            category="STRONGç±»åˆ†æ",
            title="å‘½åé€»è¾‘ç±»å‹åˆ†å¸ƒ",
            content=content,
            data=logic_counts.to_dict()
        ))
        
        # ä¿å­˜è¯¦ç»†CSV
        strong_logic_report = pd.DataFrame({
            'æ•°é‡': logic_counts,
            'ç™¾åˆ†æ¯”(%)': (logic_counts / len(strong_df) * 100).round(2)
        })
        strong_logic_report.to_csv(
            self.output_dir / "mining_strong_logic.csv",
            encoding='utf-8-sig'
        )
    
    def _analyze_weak_sources(self):
        """åˆ†æWEAKç±»çš„å¼•è¯ç‰¹å¾"""
        weak_df = self.df[self.df['resolution_type'] == 'WEAK'].copy()
        
        if len(weak_df) == 0:
            return
        
        # å®šä¹‰å¼•è¯ç±»å‹
        def get_weak_source(text):
            if re.search(r"ã€Š.*?ã€‹", text):
                return "ä¹¦è¯å¼•ç”¨"
            if re.search(r"äº‘|æ›°|è°“ä¹‹", text):
                return "å£ä¼ è®°è½½"
            if re.search(r"æŒ‰|æ³¨|æ®", text):
                return "è€ƒæ®æ³¨é‡Š"
            if re.search(r"ç›¸ä¼ |ä¼ è¯´", text):
                return "æ°‘é—´ä¼ è¯´"
            return "å…¶ä»–å¼•è¯"
        
        weak_df['source_type'] = weak_df['text'].apply(get_weak_source)
        source_counts = weak_df['source_type'].value_counts()
        
        # ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°
        content = f"""WEAKç±»å¼•è¯æ–¹å¼åˆ†æï¼š

åœ¨ {len(weak_df)} æ¡é—´æ¥å‘½åè§£é‡Šä¸­ï¼Œå¼•è¯æ–¹å¼åˆ†å¸ƒå¦‚ä¸‹ï¼š

"""
        for source, count in source_counts.items():
            pct = (count / len(weak_df) * 100)
            content += f"â€¢ **{source}**ï¼š{count} æ¡ï¼ˆ{pct:.1f}%ï¼‰\n"
        
        content += """

è¿™è¡¨æ˜å¤ä»£åœ°åè®°è½½å…·æœ‰æ˜æ˜¾çš„å¼•è¯ä¼ ç»Ÿï¼Œä½œè€…å¾€å¾€ä¸ç›´æ¥æ–­è¨€ï¼Œè€Œæ˜¯é€šè¿‡å¼•ç”¨å…¸ç±ã€è®°å½•ä¼ è¯´ç­‰æ–¹å¼å‘ˆç°å‘½åä¿¡æ¯ã€‚
"""
        
        self.insights.append(AnalysisInsight(
            category="WEAKç±»åˆ†æ",
            title="å¼•è¯æ–¹å¼ç‰¹å¾",
            content=content,
            data=source_counts.to_dict()
        ))
    
    def _analyze_none_focus(self):
        """åˆ†æNONEç±»çš„æè¿°ç»´åº¦"""
        none_df = self.df[self.df['resolution_type'] == 'NONE'].copy()
        
        if len(none_df) == 0:
            return
        
        # å®šä¹‰æè¿°é‡ç‚¹
        def get_none_focus(text):
            if re.search(r"\d+é‡Œ|\d+æ­¥|è·ç¦»|è¿œè¿‘", text):
                return "ç©ºé—´è·ç¦»"
            if re.search(r"\d+æˆ·|\d+å£|æ°‘|ç§Ÿ|è°ƒ", text):
                return "æˆ·ç±ç»æµ"
            if re.search(r"ä¸œ|è¥¿|å—|åŒ—|è‡³", text):
                return "å››è‡³æ–¹ä½"
            if re.search(r"ç½®|åºŸ|æ”¹ä¸º|å±", text):
                return "æ”¿åŒºå˜æ›´"
            return "åœ°ç†ç‰¹å¾"
        
        none_df['focus_type'] = none_df['text'].apply(get_none_focus)
        focus_counts = none_df['focus_type'].value_counts()
        
        # ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°
        content = f"""NONEç±»æè¿°ç»´åº¦åˆ†æï¼š

åœ¨ {len(none_df)} æ¡éå‘½åè§£é‡Šè®°å½•ä¸­ï¼Œæè¿°é‡ç‚¹åˆ†å¸ƒå¦‚ä¸‹ï¼š

"""
        for focus, count in focus_counts.items():
            pct = (count / len(none_df) * 100)
            content += f"â€¢ **{focus}**ï¼š{count} æ¡ï¼ˆ{pct:.1f}%ï¼‰\n"
        
        content += """

è¿™äº›è®°å½•è™½ä¸åŒ…å«å‘½ååŸå› ï¼Œä½†æä¾›äº†ä¸°å¯Œçš„åœ°ç†ã€è¡Œæ”¿ã€ç»æµç­‰èƒŒæ™¯ä¿¡æ¯ã€‚
"""
        
        self.insights.append(AnalysisInsight(
            category="NONEç±»åˆ†æ",
            title="æè¿°ç»´åº¦åˆ†å¸ƒ",
            content=content,
            data=focus_counts.to_dict()
        ))
    
    def _analyze_comprehensive_stats(self):
        """ç»¼åˆç»Ÿè®¡åˆ†æ"""
        # æ–‡æœ¬é•¿åº¦ç»Ÿè®¡
        length_stats = self.df.groupby('resolution_type')['text_len'].agg([
            ('å¹³å‡é•¿åº¦', 'mean'),
            ('æœ€çŸ­', 'min'),
            ('æœ€é•¿', 'max'),
            ('ä¸­ä½æ•°', 'median')
        ]).round(1)
        
        content = """æ–‡æœ¬é•¿åº¦ç»¼åˆç»Ÿè®¡ï¼š

å„ç±»åˆ«è®°å½•çš„å¹³å‡æ–‡æœ¬é•¿åº¦å¦‚ä¸‹ï¼š

"""
        for label, row in length_stats.iterrows():
            content += f"â€¢ **{label}ç±»**ï¼šå¹³å‡ {row['å¹³å‡é•¿åº¦']:.0f} å­—ï¼ˆèŒƒå›´ï¼š{row['æœ€çŸ­']:.0f}-{row['æœ€é•¿']:.0f}å­—ï¼‰\n"
        
        # æ¥æºæ–‡çŒ®åˆ†å¸ƒ
        source_counts = self.df['source'].value_counts().head(10)
        content += f"\næ•°æ®æ¥æºæ–‡çŒ®åˆ†å¸ƒï¼ˆTop 10ï¼‰ï¼š\n\n"
        for source, count in source_counts.items():
            content += f"â€¢ {source}ï¼š{count} æ¡\n"
        
        self.insights.append(AnalysisInsight(
            category="ç»¼åˆç»Ÿè®¡",
            title="æ–‡æœ¬é•¿åº¦ä¸æ¥æºåˆ†å¸ƒ",
            content=content,
            data={
                "length_stats": length_stats.to_dict(),
                "top_sources": source_counts.to_dict()
            }
        ))
        
        # ä¿å­˜ç»Ÿè®¡æ‘˜è¦
        summary = self.df.groupby('resolution_type').agg({
            'placename': 'count',
            'text_len': 'mean'
        }).rename(columns={'placename': 'Count', 'text_len': 'Avg_Length'})
        summary.to_csv(self.output_dir / "analysis_summary.csv", encoding='utf-8-sig')
    
    def _generate_visualizations(self):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        print("ğŸ“Š æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        # 1. åˆ†ç±»åˆ†å¸ƒé¥¼å›¾
        plt.figure(figsize=(10, 8))
        counts = self.df['resolution_type'].value_counts()
        plt.pie(counts, labels=counts.index, autopct='%1.1f%%', 
                startangle=140, colors=sns.color_palette("pastel"))
        plt.title("åœ°åè®°å½•åˆ†ç±»åˆ†å¸ƒ", fontsize=16, fontweight='bold')
        plt.savefig(self.output_dir / "stat_category_pie.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. æ–‡æœ¬é•¿åº¦ç®±çº¿å›¾
        plt.figure(figsize=(10, 6))
        sns.boxplot(x='resolution_type', y='text_len', data=self.df, palette="Set2")
        plt.title("å„ç±»åˆ«æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ", fontsize=16, fontweight='bold')
        plt.xlabel("åˆ†ç±»æ ‡ç­¾", fontsize=12)
        plt.ylabel("å­—ç¬¦é•¿åº¦", fontsize=12)
        plt.savefig(self.output_dir / "stat_length_boxplot.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. ä¸‰åˆä¸€æ·±åº¦åˆ†æå›¾
        fig, axes = plt.subplots(1, 3, figsize=(20, 7))
        
        # STRONGå­ç±»å‹
        strong_df = self.df[self.df['resolution_type'] == 'STRONG'].copy()
        if len(strong_df) > 0:
            strong_df['logic_type'] = strong_df['text'].apply(self._get_strong_subtype_simple)
            logic_counts = strong_df['logic_type'].value_counts()
            sns.barplot(x=logic_counts.index, y=logic_counts.values, 
                       ax=axes[0], palette="viridis")
            axes[0].set_title("STRONGç±»ï¼šå‘½åé€»è¾‘åˆ†å¸ƒ", fontsize=14)
            axes[0].tick_params(axis='x', rotation=45)
        
        # WEAKå¼•è¯æ–¹å¼
        weak_df = self.df[self.df['resolution_type'] == 'WEAK'].copy()
        if len(weak_df) > 0:
            weak_df['source_type'] = weak_df['text'].apply(self._get_weak_source_simple)
            weak_counts = weak_df['source_type'].value_counts()
            axes[1].pie(weak_counts, labels=weak_counts.index, 
                       autopct='%1.1f%%', startangle=140,
                       colors=sns.color_palette("pastel"))
            axes[1].set_title("WEAKç±»ï¼šå¼•è¯æ–¹å¼", fontsize=14)
        
        # NONEæè¿°é‡ç‚¹
        none_df = self.df[self.df['resolution_type'] == 'NONE'].copy()
        if len(none_df) > 0:
            none_df['focus_type'] = none_df['text'].apply(self._get_none_focus_simple)
            none_counts = none_df['focus_type'].value_counts()
            sns.barplot(x=none_counts.index, y=none_counts.values, 
                       ax=axes[2], palette="magma")
            axes[2].set_title("NONEç±»ï¼šæè¿°é‡ç‚¹", fontsize=14)
            axes[2].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / "mining_deep_analysis.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        print("å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆ")
    
    def _export_rag_documents(self):
        """å¯¼å‡ºRAGå‹å¥½çš„æ–‡æ¡£"""
        print("ğŸ“„ æ­£åœ¨ç”ŸæˆRAGçŸ¥è¯†åº“æ–‡æ¡£...")
        
        # 1. å¯¼å‡ºä¸ºå•ä¸ªMarkdownæ–‡æ¡£
        md_content = "# å¤ç±åœ°åæ•°æ®åˆ†ææŠ¥å‘Š\n\n"
        md_content += f"ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        md_content += "---\n\n"
        
        for insight in self.insights:
            md_content += f"## {insight.title}\n\n"
            md_content += f"**ç±»åˆ«**: {insight.category}\n\n"
            md_content += insight.content
            md_content += "\n\n---\n\n"
        
        with open(self.output_dir / "analysis_insights.md", "w", encoding="utf-8") as f:
            f.write(md_content)
        
        # 2. å¯¼å‡ºä¸ºJSONï¼ˆç»“æ„åŒ–æ•°æ®ï¼‰
        insights_json = [
            {
                "category": insight.category,
                "title": insight.title,
                "content": insight.content,
                "data": insight.data
            }
            for insight in self.insights
        ]
        
        with open(self.output_dir / "analysis_insights.json", "w", encoding="utf-8") as f:
            json.dump(insights_json, f, ensure_ascii=False, indent=2)
        
        # 3. å¯¼å‡ºä¸ºCSVï¼ˆä¾›RAGç›´æ¥åŠ è½½ï¼‰
        insights_df = pd.DataFrame([
            {
                "category": insight.category,
                "title": insight.title,
                "content": insight.content
            }
            for insight in self.insights
        ])
        insights_df.to_csv(
            self.output_dir / "analysis_insights.csv",
            index=False,
            encoding='utf-8-sig'
        )
        
        print("RAGçŸ¥è¯†åº“æ–‡æ¡£å·²ç”Ÿæˆ:")
        print(f"  â€¢ {self.output_dir / 'analysis_insights.md'}")
        print(f"  â€¢ {self.output_dir / 'analysis_insights.json'}")
        print(f"  â€¢ {self.output_dir / 'analysis_insights.csv'}")
    
    # è¾…åŠ©æ–¹æ³•ï¼ˆç®€åŒ–ç‰ˆåˆ†ç±»å‡½æ•°ï¼‰
    def _get_strong_subtype_simple(self, text):
        if re.search(r"å±±|å²­|å³°|å²©|å²³|å†ˆ", text): return "è‡ªç„¶å±±å²³"
        if re.search(r"æ°´|æ²³|æ±Ÿ|å·|æºª|æ± |æ¹–|æ½­|æº", text): return "è‡ªç„¶æ°´æ–‡"
        if re.search(r"äºº|ç‹|å…¬|å§“|æ°|çš‡|å|å¦ƒ", text): return "äººç‰©å§“æ°"
        if re.search(r"æ•…|æ—§|æ”¹|å¾™|åºŸ|ç½¢|æ–°ç½®", text): return "å†å²æ²¿é©"
        if re.search(r"å–.*?ä¹‹ä¹‰|å–.*?åä¹‹|ä»¥.*?ä¸ºå", text): return "æŠ½è±¡è¯­ä¹‰"
        return "å…¶ä»–"
    
    def _get_weak_source_simple(self, text):
        if re.search(r"ã€Š.*?ã€‹", text): return "ä¹¦è¯å¼•ç”¨"
        if re.search(r"äº‘|æ›°|è°“ä¹‹", text): return "å£ä¼ è®°è½½"
        if re.search(r"æŒ‰|æ³¨|æ®", text): return "è€ƒæ®æ³¨é‡Š"
        return "å…¶ä»–å¼•è¯"
    
    def _get_none_focus_simple(self, text):
        if re.search(r"\d+é‡Œ|\d+æ­¥|è·ç¦»|è¿œè¿‘", text): return "ç©ºé—´è·ç¦»"
        if re.search(r"\d+æˆ·|\d+å£|æ°‘|ç§Ÿ|è°ƒ", text): return "æˆ·ç±ç»æµ"
        if re.search(r"ä¸œ|è¥¿|å—|åŒ—|è‡³", text): return "å››è‡³æ–¹ä½"
        if re.search(r"ç½®|åºŸ|æ”¹ä¸º|å±", text): return "æ”¿åŒºå˜æ›´"
        return "åœ°ç†ç‰¹å¾"


def main():
    """ä¸»å‡½æ•°"""
    input_file = "batch_classification_results.csv"
    
    if not os.path.exists(input_file):
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ {input_file}")
        return
    
    analyzer = EnhancedDataAnalyzer(input_file)
    analyzer.run_full_analysis()
    
    print("\n" + "="*60)
    print("åˆ†æå®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜è‡³ results/ ç›®å½•")
    print("="*60)


if __name__ == "__main__":
    main()